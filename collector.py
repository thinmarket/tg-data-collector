#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Telegram Safe Channel Collector - –° –ê–í–¢–û–°–û–•–†–ê–ù–ï–ù–ò–ï–ú
"""

import asyncio
import pandas as pd
from telethon import TelegramClient, errors
from telethon.tl.functions.channels import GetParticipantsRequest
from telethon.tl.types import ChannelParticipantsSearch
import os
from datetime import datetime
import logging
import json

# ========== –ù–ê–°–¢–†–û–ô–ö–ò ==========
API_ID = 12345678
API_HASH = '–í–≤–µ–¥–∏—Ç–µ —Å–≤–æ–π API_HASH'
CHANNEL_USERNAME = '–í–≤–µ–¥–∏—Ç–µ username –∫–∞–Ω–∞–ª–∞ –±–µ–∑ @'
# ================================

ALPHABET = [
    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',
    'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',
    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',
    '–∞', '–±', '–≤', '–≥', '–¥', '–µ', '—ë', '–∂', '–∑', '–∏', '–π', '–∫', '–ª', '–º',
    '–Ω', '–æ', '–ø', '—Ä', '—Å', '—Ç', '—É', '—Ñ', '—Ö', '—Ü', '—á', '—à', '—â', '—ä',
    '—ã', '—å', '—ç', '—é', '—è'
]

DELAY_BETWEEN_REQUESTS = 10
BATCH_SIZE = 3
BATCH_PAUSE = 120
DAILY_LIMIT = 80

OUTPUT_DIR = 'telegram_safe_collector'
PHOTOS_DIR = os.path.join(OUTPUT_DIR, 'photos')
PROGRESS_FILE = os.path.join(OUTPUT_DIR, f'{CHANNEL_USERNAME}_progress.json')
os.makedirs(PHOTOS_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

class SafeCollector:
    def __init__(self):
        self.client = TelegramClient('session_qr', API_ID, API_HASH)
        self.channel = None
        self.existing_users = {}
        self.new_users = {}
        self.temp_new_users = {}  # –¥–ª—è –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        self.stats = {
            'total_before': 0,
            'new_found': 0,
            'total_after': 0,
            'requests_today': 0,
            'last_run': None
        }
        self.csv_path = os.path.join(OUTPUT_DIR, f'{CHANNEL_USERNAME}_data.csv')
    
    def load_existing_data(self):
        if os.path.exists(self.csv_path):
            try:
                df = pd.read_csv(self.csv_path)
                for _, row in df.iterrows():
                    self.existing_users[row['user_id']] = dict(row)
                logger.info(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π: {len(self.existing_users)}")
                self.stats['total_before'] = len(self.existing_users)
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CSV: {e}")
    
    def load_progress(self):
        if os.path.exists(PROGRESS_FILE):
            try:
                with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
                    progress = json.load(f)
                    self.processed_letters = progress.get('processed_letters', [])
                    self.stats['requests_today'] = progress.get('requests_today', 0)
                    self.stats['last_run'] = progress.get('last_run')
                    
                    if self.stats['last_run']:
                        last = datetime.fromisoformat(self.stats['last_run'])
                        if (datetime.now() - last).days >= 1:
                            self.stats['requests_today'] = 0
                            logger.info("üìÖ –ù–æ–≤—ã–π –¥–µ–Ω—å - —Å—á–µ—Ç—á–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–±–Ω—É–ª–µ–Ω")
                    
                    logger.info(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–æ–≥—Ä–µ—Å—Å: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(self.processed_letters)} –±—É–∫–≤")
                    logger.info(f"üìä –ó–∞–ø—Ä–æ—Å–æ–≤ —Å–µ–≥–æ–¥–Ω—è: {self.stats['requests_today']}/{DAILY_LIMIT}")
            except:
                self.processed_letters = []
        else:
            self.processed_letters = []
    
    def save_progress(self):
        progress = {
            'processed_letters': self.processed_letters,
            'requests_today': self.stats['requests_today'],
            'last_run': datetime.now().isoformat()
        }
        with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
            json.dump(progress, f, ensure_ascii=False, indent=2)
    
    def save_batch(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –∑–∞ –±–∞—Ç—á –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
        if self.temp_new_users:
            temp_df = pd.DataFrame(list(self.temp_new_users.values()))
            if os.path.exists(self.csv_path):
                existing_df = pd.read_csv(self.csv_path)
                combined_df = pd.concat([existing_df, temp_df], ignore_index=True)
                combined_df = combined_df.drop_duplicates(subset=['user_id'], keep='last')
                combined_df.to_csv(self.csv_path, index=False, encoding='utf-8-sig')
            else:
                temp_df.to_csv(self.csv_path, index=False, encoding='utf-8-sig')
            logger.info(f"üíæ –ê–í–¢–û–°–û–•–†–ê–ù–ï–ù–ò–ï: +{len(self.temp_new_users)} –Ω–æ–≤—ã—Ö (–≤—Å–µ–≥–æ {len(self.existing_users) + len(self.new_users)})")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º existing_users –¥–ª—è —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏
            for uid in self.temp_new_users:
                self.existing_users[uid] = self.temp_new_users[uid]
            
            self.temp_new_users = {}
    
    async def start(self):
        await self.client.connect()
        if not await self.client.is_user_authorized():
            logger.error("‚ùå –ù–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω. –°–Ω–∞—á–∞–ª–∞ –≤–æ–π–¥–∏ —á–µ—Ä–µ–∑ QR-–∫–æ–¥.")
            return False
        me = await self.client.get_me()
        logger.info(f"‚úÖ –ê–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω: {me.first_name}")
        return True
    
    async def get_channel(self):
        try:
            self.channel = await self.client.get_entity(CHANNEL_USERNAME)
            logger.info(f"üì¢ –ö–∞–Ω–∞–ª: {self.channel.title}")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return False
    
    async def search_by_query(self, query):
        try:
            participants = await self.client(GetParticipantsRequest(
                channel=self.channel,
                filter=ChannelParticipantsSearch(query),
                offset=0,
                limit=200,
                hash=0
            ))
            return participants.users
        except errors.FloodWaitError as e:
            wait = e.seconds
            logger.warning(f"‚ö†Ô∏è FloodWait: {wait} —Å–µ–∫")
            await asyncio.sleep(wait)
            return await self.search_by_query(query)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ '{query}': {e}")
            return []
    
    async def download_photo(self, user):
        try:
            if user.photo:
                path = await self.client.download_profile_photo(
                    user, 
                    file=os.path.join(PHOTOS_DIR, f'{user.id}.jpg')
                )
                if path:
                    return f'photos/{user.id}.jpg'
        except:
            pass
        return None
    
    async def process_letter(self, letter):
        logger.info(f"üî§ –ü–æ–∏—Å–∫: '{letter}' (–∑–∞–ø—Ä–æ—Å {self.stats['requests_today'] + 1}/{DAILY_LIMIT})")
        
        users = await self.search_by_query(letter)
        batch_new = 0
        
        for user in users:
            if user.id not in self.existing_users and user.id not in self.new_users:
                photo_path = await self.download_photo(user)
                
                user_data = {
                    'user_id': user.id,
                    'username': user.username,
                    'first_name': user.first_name,
                    'last_name': user.last_name,
                    'full_name': f"{user.first_name or ''} {user.last_name or ''}".strip(),
                    'phone': user.phone,
                    'is_bot': user.bot,
                    'is_premium': getattr(user, 'premium', False),
                    'photo': photo_path
                }
                
                self.temp_new_users[user.id] = user_data
                self.new_users[user.id] = user_data
                self.stats['new_found'] += 1
                batch_new += 1
                
                if self.stats['new_found'] % 10 == 0:
                    logger.info(f"‚ú® –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö: {self.stats['new_found']}")
        
        self.processed_letters.append(letter)
        self.stats['requests_today'] += 1
        
        return batch_new
    
    async def run_collection(self):
        self.load_existing_data()
        self.load_progress()
        
        remaining_letters = [l for l in ALPHABET if l not in self.processed_letters]
        
        if not remaining_letters:
            logger.info("‚úÖ –í—Å–µ –±—É–∫–≤—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
            return
        
        logger.info(f"‚è≥ –ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä. –û—Å—Ç–∞–ª–æ—Å—å –±—É–∫–≤: {len(remaining_letters)}")
        logger.info(f"‚è± –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏: {DELAY_BETWEEN_REQUESTS} —Å–µ–∫")
        logger.info(f"üì¶ –ë–∞—Ç—á: {BATCH_SIZE} –∑–∞–ø—Ä–æ—Å–æ–≤, –∑–∞—Ç–µ–º –ø–∞—É–∑–∞ {BATCH_PAUSE} —Å–µ–∫")
        logger.info(f"üìä –î–Ω–µ–≤–Ω–æ–π –ª–∏–º–∏—Ç: {DAILY_LIMIT} –∑–∞–ø—Ä–æ—Å–æ–≤")
        logger.info(f"üìÅ CSV —Ñ–∞–π–ª: {self.csv_path}")
        
        answer = input(f"\n–ù–∞—á–∞—Ç—å —Å–±–æ—Ä (–æ—Å—Ç–∞–ª–æ—Å—å {len(remaining_letters)} –±—É–∫–≤)? (–¥–∞/–Ω–µ—Ç): ")
        if answer.lower() != '–¥–∞':
            logger.info("–û—Ç–º–µ–Ω–µ–Ω–æ")
            return
        
        processed_in_session = 0
        
        for i, letter in enumerate(remaining_letters, 1):
            if self.stats['requests_today'] >= DAILY_LIMIT:
                logger.warning(f"‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –¥–Ω–µ–≤–Ω–æ–π –ª–∏–º–∏—Ç ({DAILY_LIMIT} –∑–∞–ø—Ä–æ—Å–æ–≤)")
                logger.info(f"üåô –ü—Ä–æ–¥–æ–ª–∂–∏–º –∑–∞–≤—Ç—Ä–∞. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–µ–≥–æ–¥–Ω—è: {processed_in_session} –±—É–∫–≤")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–∞—Ç—á
                self.save_batch()
                self.save_progress()
                return
            
            await self.process_letter(letter)
            processed_in_session += 1
            self.save_progress()
            
            if i < len(remaining_letters):
                if processed_in_session % BATCH_SIZE == 0:
                    logger.info(f"‚è∏ –î–õ–ò–¢–ï–õ–¨–ù–ê–Ø –ü–ê–£–ó–ê {BATCH_PAUSE} —Å–µ–∫")
                    logger.info("‚òï –û—Ç–¥—ã—Ö–∞–µ–º...")
                    
                    # –ê–í–¢–û–°–û–•–†–ê–ù–ï–ù–ò–ï!
                    self.save_batch()
                    
                    await asyncio.sleep(BATCH_PAUSE)
                else:
                    logger.info(f"‚è± –ü–∞—É–∑–∞ {DELAY_BETWEEN_REQUESTS} —Å–µ–∫")
                    await asyncio.sleep(DELAY_BETWEEN_REQUESTS)
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        self.save_batch()
        
        logger.info("=" * 50)
        logger.info("‚úÖ –°–ï–°–°–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
        logger.info(f"üìä –ë—ã–ª–æ: {self.stats['total_before']}")
        logger.info(f"‚ú® –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö: {self.stats['new_found']}")
        logger.info(f"üìä –°—Ç–∞–ª–æ: {self.stats['total_before'] + self.stats['new_found']}")
        logger.info(f"üìÖ –ó–∞–ø—Ä–æ—Å–æ–≤ —Å–µ–≥–æ–¥–Ω—è: {self.stats['requests_today']}")
        logger.info("=" * 50)
    
    async def close(self):
        await self.client.disconnect()

async def main():
    logger.info("=" * 60)
    logger.info("üõ°Ô∏è SAFE TELEGRAM COLLECTOR (–° –ê–í–¢–û–°–û–•–†–ê–ù–ï–ù–ò–ï–ú)")
    logger.info("=" * 60)
    
    collector = SafeCollector()
    
    try:
        if not await collector.start():
            return
        if not await collector.get_channel():
            return
        
        await collector.run_collection()
        
    except KeyboardInterrupt:
        logger.info("\n‚èπ –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        collector.save_batch()  # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–µ
        collector.save_progress()
    finally:
        await collector.close()

if __name__ == '__main__':

    asyncio.run(main())
